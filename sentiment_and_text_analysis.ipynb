{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentiment and text analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEaJ12QD1iWz"
      },
      "source": [
        "Note : Used google collab for this assignment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRivKHt0L7P9"
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import sys\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "import itertools\n",
        "from itertools import chain\n",
        "from collections import Counter\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import RegexpTokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYBjSBYUmBri"
      },
      "source": [
        "\n",
        "#nltk.download('punkt')\n",
        "#nltk.download('stopwords')\n",
        "#nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIcNuH1wdT89"
      },
      "source": [
        "#pip install textstat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2vbXuA_jGY7"
      },
      "source": [
        "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.45 Safari/537.36'}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aR12ti4Q_OVn"
      },
      "source": [
        "# Data Extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "Fbaz8Wxx_lPw",
        "outputId": "dec14d2c-90cb-4168-f69f-897b8f938697"
      },
      "source": [
        "df = pd.read_csv(\"/content/Input.csv\")\n",
        "df = pd.DataFrame(df)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>URL_ID</th>\n",
              "      <th>URL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>https://insights.blackcoffer.com/how-is-login-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>https://insights.blackcoffer.com/how-does-ai-h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>https://insights.blackcoffer.com/ai-and-its-im...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>https://insights.blackcoffer.com/how-do-deep-l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>https://insights.blackcoffer.com/how-artificia...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165</th>\n",
              "      <td>167</td>\n",
              "      <td>https://insights.blackcoffer.com/role-big-data...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>166</th>\n",
              "      <td>168</td>\n",
              "      <td>https://insights.blackcoffer.com/sales-forecas...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>167</th>\n",
              "      <td>169</td>\n",
              "      <td>https://insights.blackcoffer.com/detect-data-e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>168</th>\n",
              "      <td>170</td>\n",
              "      <td>https://insights.blackcoffer.com/data-exfiltra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>169</th>\n",
              "      <td>171</td>\n",
              "      <td>https://insights.blackcoffer.com/impacts-of-co...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>170 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     URL_ID                                                URL\n",
              "0         1  https://insights.blackcoffer.com/how-is-login-...\n",
              "1         2  https://insights.blackcoffer.com/how-does-ai-h...\n",
              "2         3  https://insights.blackcoffer.com/ai-and-its-im...\n",
              "3         4  https://insights.blackcoffer.com/how-do-deep-l...\n",
              "4         5  https://insights.blackcoffer.com/how-artificia...\n",
              "..      ...                                                ...\n",
              "165     167  https://insights.blackcoffer.com/role-big-data...\n",
              "166     168  https://insights.blackcoffer.com/sales-forecas...\n",
              "167     169  https://insights.blackcoffer.com/detect-data-e...\n",
              "168     170  https://insights.blackcoffer.com/data-exfiltra...\n",
              "169     171  https://insights.blackcoffer.com/impacts-of-co...\n",
              "\n",
              "[170 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7483
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkeSKIVyAV8v",
        "outputId": "e1c11956-f4f8-4bf9-fa8d-9eb46272ddac"
      },
      "source": [
        "df['URL']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      https://insights.blackcoffer.com/how-is-login-...\n",
              "1      https://insights.blackcoffer.com/how-does-ai-h...\n",
              "2      https://insights.blackcoffer.com/ai-and-its-im...\n",
              "3      https://insights.blackcoffer.com/how-do-deep-l...\n",
              "4      https://insights.blackcoffer.com/how-artificia...\n",
              "                             ...                        \n",
              "165    https://insights.blackcoffer.com/role-big-data...\n",
              "166    https://insights.blackcoffer.com/sales-forecas...\n",
              "167    https://insights.blackcoffer.com/detect-data-e...\n",
              "168    https://insights.blackcoffer.com/data-exfiltra...\n",
              "169    https://insights.blackcoffer.com/impacts-of-co...\n",
              "Name: URL, Length: 170, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 7484
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glWPKAmFnLv4"
      },
      "source": [
        "#function to scrape content and save in a file.\n",
        "\n",
        "def get_title(url):\n",
        "  r = requests.get(url, headers = headers)\n",
        "  soup = BeautifulSoup(r.text, 'html.parser')\n",
        "  art_title = soup.find( 'span',{ 'class' : \"td-bred-no-url-last\"}).text\n",
        "  art_content  = soup.find( 'div',{ 'class' : \"td-post-content\"}).text\n",
        "\n",
        "  f = open(\"170.txt\", \"w\")\n",
        "  f.writelines(art_title)\n",
        "  f.writelines(art_content)\n",
        "  f.close()\n",
        "\n",
        "  \n",
        "get_title('https://insights.blackcoffer.com/impacts-of-covid-19-on-vegetable-vendors-and-food-stalls/')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8jx2wgtCSwZ"
      },
      "source": [
        "# removing last line of the txt file (Author name)\n",
        "\n",
        "with open(\"/content/170.txt\",\"r+\") as f:\n",
        "    text = f.readlines()\n",
        "    f.seek(0)\n",
        "    f.truncate()\n",
        "    f.writelines(text[:-1])\n",
        "    f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fzddl7h5QUx"
      },
      "source": [
        "# 1. Sentiment Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWUIL58R3T7f"
      },
      "source": [
        "# Remove stop words from txt file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1lE8POO1wy7"
      },
      "source": [
        "k = []\n",
        "z = []\n",
        "\n",
        "with open('/content/stopWords.txt', 'r') as x:\n",
        "    for l in x:\n",
        "        for word in l.split():\n",
        "           k.append(word)\n",
        "\n",
        "# tokenizing words without using NLTK\n",
        "\n",
        "#with open('2.txt', 'r') as f:\n",
        "#    for line in f:\n",
        "#        for word in line.split():\n",
        "#           z.append(word)\n",
        "\n",
        "\n",
        "\n",
        "# tokenzing words using NLTK\n",
        "\n",
        "with open('170.txt', 'r') as f:\n",
        "  for lines in f:  \n",
        "    line = f.read()\n",
        "    #print(lines)\n",
        "    z = word_tokenize(line)\n",
        "\n",
        "    \n",
        "p = [t for t in z if t.upper() not in k]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5D57HTALjRa"
      },
      "source": [
        "master_df = pd.read_csv(\"/content/masterDict.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAs2yVwVbvbi"
      },
      "source": [
        "# list of negative words\n",
        "neg_df = master_df[master_df['Negative'] == 2009]['Word'].to_list()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApVVzOyzcr4-"
      },
      "source": [
        "# list of positive words\n",
        "pos_df  = master_df[master_df['Positive'] == 2009]['Word'].to_list()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gf9Wn0TzeZK8",
        "outputId": "9e60f353-8eac-4657-e86e-c619ffa18945"
      },
      "source": [
        "# pos score\n",
        "def pos_scr():\n",
        "  pos_lst = [1 for t in p if t.upper() in pos_df]\n",
        "  pos_scr = sum(pos_lst)\n",
        "  return(pos_scr)\n",
        "pos_scr()  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 7492
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_bVhwa2dlZj",
        "outputId": "7b97ac98-554f-45b1-fec8-c0291b28fdf7"
      },
      "source": [
        "# neg score\n",
        "def neg_scr():\n",
        "  neg_lst = [-1 for t in p if t.upper() in neg_df]\n",
        "  neg_scr = sum(neg_lst)* -1\n",
        "  return(neg_scr)  \n",
        "neg_scr()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 7493
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qql1Dk5Oh_uB",
        "outputId": "c58ce7d6-8dc3-44d6-dbfb-03f1c38eb104"
      },
      "source": [
        "# polar score\n",
        "def polar_scr():\n",
        "  polar_score = (pos_scr() - neg_scr()) / ((pos_scr() + neg_scr())  + 0.000001)\n",
        "  return(polar_score)\n",
        "\n",
        "polar_scr()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.2857142653061239"
            ]
          },
          "metadata": {},
          "execution_count": 7494
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUctGV6ji3qS",
        "outputId": "81a18b22-474d-41d2-c37f-379d2fdaef6d"
      },
      "source": [
        "#subjectivity score\n",
        "def sub_scr():\n",
        "  sub_score = (pos_scr() + neg_scr()) / ((len(p)) + 0.000001)\n",
        "  return(sub_score)\n",
        "sub_scr()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.02707930362267059"
            ]
          },
          "metadata": {},
          "execution_count": 7495
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUqyHEnoRh8S"
      },
      "source": [
        "# 2. Analysis of Readibility"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnB3uq50RsTA",
        "outputId": "85248b37-b75a-44b3-a256-cb369d9337e0"
      },
      "source": [
        "#Average Sentence Length / average number of words per sentence\n",
        "\n",
        "with open('170.txt', 'r') as file:\n",
        "  lines = file.read()\n",
        "#Total_words = len(file_contents.split())\n",
        "  tokenizer = RegexpTokenizer(r'\\w+')\n",
        "  word_tokens = tokenizer.tokenize(lines)\n",
        "\n",
        "def avg_slen():\n",
        "      Total_words = len(word_tokens)\n",
        "      total_sentences =  lines.count('.')\n",
        "      return(Total_words/total_sentences)\n",
        "avg_slen()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29.807692307692307"
            ]
          },
          "metadata": {},
          "execution_count": 7496
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGEyT4hi4wbg"
      },
      "source": [
        "import spacy\n",
        "import textstat\n",
        "from textstat.textstat import textstatistics,legacy_round\n",
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7o4AaN63X2H",
        "outputId": "7b26759b-c74d-4215-d3dd-a9939e795db9"
      },
      "source": [
        "# Count of complex words\n",
        "def comp_cnt():\n",
        "  com_cnt = textstat.difficult_words(lines)\n",
        "  return(com_cnt)\n",
        "comp_cnt()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "139"
            ]
          },
          "metadata": {},
          "execution_count": 7498
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wx-Wd7Pb9fCJ",
        "outputId": "e124dce6-92e8-470d-9117-bff816879b3e"
      },
      "source": [
        "## % of complex words\n",
        "def comp_wrds():\n",
        "  Total_words = len(word_tokens)\n",
        "  com_wrds = comp_cnt()/Total_words\n",
        "  return(com_wrds)\n",
        "comp_wrds()  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.17935483870967742"
            ]
          },
          "metadata": {},
          "execution_count": 7499
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGeBvT1o9F6M",
        "outputId": "1ef39606-8573-4355-f9d8-7eeaa9a099f0"
      },
      "source": [
        "# fog index\n",
        "\n",
        "def fog_idx():\n",
        "  fg_ind = 0.4*(avg_slen() + comp_wrds())\n",
        "  print(fg_ind)\n",
        "fog_idx()  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11.994818858560794\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEVho73Kt3lF"
      },
      "source": [
        "\n",
        "# Word Count"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjgGlv3-tyQy",
        "outputId": "7601abff-2456-4a0e-fd9e-b130d7cac0da"
      },
      "source": [
        "# using nltk to exclude stopwords, exclude punctuations.\n",
        "# then find number of words\n",
        "\n",
        "def word_cnt():\n",
        "  stop_words = set(stopwords.words('english'))\n",
        "  all_words = [w for w in word_tokens if not w.lower() in stop_words]\n",
        "  \n",
        "  count_words = len(all_words)\n",
        "  return(count_words)\n",
        "\n",
        "word_cnt()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "440"
            ]
          },
          "metadata": {},
          "execution_count": 7501
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Q9fIWXV0Pho"
      },
      "source": [
        "# Syllable count per word"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71-Ew1LDHRzK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4271cf9a-5dfc-4dd3-8bcd-553721042d7c"
      },
      "source": [
        "# avg number of syllables per word\n",
        "def syl_cnt():\n",
        "  vowels = 'aeiou'\n",
        "  countVowels = 0\n",
        "  for words in word_tokens:\n",
        "    for letter in words:\n",
        "      if letter in vowels:\n",
        "        countVowels += 1\n",
        "    if words.endswith(\"ed\"):\n",
        "      countVowels -=1\n",
        "    if words.endswith(\"es\"):\n",
        "      countVowels -=1\n",
        "  return(countVowels/len(word_tokens)) \n",
        "\n",
        "syl_cnt()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.8387096774193548"
            ]
          },
          "metadata": {},
          "execution_count": 7502
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYL4RIUT24v-"
      },
      "source": [
        "# Personal Pronouns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KppaQDVO3AtE",
        "outputId": "bab8b3c3-83e7-48a7-88e2-c8c2f007af99"
      },
      "source": [
        "def prp_cnt():\n",
        "  if 'US' in word_tokens:\n",
        "    word_tokens.remove('US')\n",
        "  tagged = nltk.pos_tag(word_tokens)\n",
        "\n",
        "  counts = Counter(tag for word,tag in tagged)\n",
        "  filt_keys = ['PRP']\n",
        "  res = [counts[key] for key in filt_keys]\n",
        "  strings = [str(res) for res in res]\n",
        "  a_string = \"\". join(strings)\n",
        "  an_integer = int(a_string)\n",
        "  return(an_integer)\n",
        "\n",
        "prp_cnt()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 7503
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpL5eXCRf5PL"
      },
      "source": [
        "# Avg Word length"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elcMZb9VD7E7",
        "outputId": "abf4d22b-3801-430a-a7ad-9bda35e3b0e7"
      },
      "source": [
        "def avg_wrlen():\n",
        "  letr_cnt = int()\n",
        "  Total_words = len(word_tokens)\n",
        "  for words in word_tokens:\n",
        "      for letters in words:\n",
        "          letr_cnt +=1\n",
        "  \n",
        "  avg_wrlen = letr_cnt/Total_words\n",
        "  return(avg_wrlen)\n",
        "avg_wrlen()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.078709677419355"
            ]
          },
          "metadata": {},
          "execution_count": 7504
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZMgWGWyTSaf"
      },
      "source": [
        "# Result input to excel sheet\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXxuaHqFVI5L"
      },
      "source": [
        "import openpyxl\n",
        "from openpyxl import load_workbook\n",
        "import string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_Q7XU9zVJ7C"
      },
      "source": [
        "excel_file = pd.read_excel('output.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFfZNB0IVRqR",
        "outputId": "fc980d38-c78a-4f5d-dfa1-eec622f7e9eb"
      },
      "source": [
        "\n",
        "wb = load_workbook('output.xlsx')\n",
        "sheet = wb['Sheet1']\n",
        "\n",
        "\n",
        "sheet['C171'] = pos_scr()\n",
        "sheet['D171'] = neg_scr()\n",
        "sheet['E171'] = polar_scr()\n",
        "sheet['F171'] = sub_scr()\n",
        "sheet['G171'] = avg_slen()\n",
        "sheet['H171'] = comp_wrds() \n",
        "sheet['I171'] = fog_idx()\n",
        "sheet['J171'] = avg_slen()\n",
        "sheet['K171'] = comp_cnt()\n",
        "sheet['L171'] = word_cnt()\n",
        "sheet['M171'] = syl_cnt()\n",
        "sheet['N171'] = prp_cnt()\n",
        "sheet['O171'] = avg_wrlen()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11.994818858560794\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KP7NXfdrkkHc"
      },
      "source": [
        "wb.save('output.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}